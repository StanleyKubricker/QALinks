{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c3031d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "\n",
    "def estimate_reading_time(text):\n",
    "    num_words = len(text.split())\n",
    "    flesch_score = textstat.flesch_reading_ease(text)\n",
    "\n",
    "    # Adjust words-per-minute rate based on Flesch score\n",
    "    if flesch_score >= 90.0:\n",
    "        wpm = 250  # Very easy text\n",
    "    elif flesch_score >= 80.0:\n",
    "        wpm = 220  # Easy text\n",
    "    elif flesch_score >= 70.0:\n",
    "        wpm = 200  # Fairly easy text\n",
    "    elif flesch_score >= 60.0:\n",
    "        wpm = 180  # Standard text\n",
    "    else:\n",
    "        wpm = 150  # Fairly difficult, difficult, and very confusing text\n",
    "\n",
    "    reading_time_min = num_words / wpm\n",
    "    return reading_time_min\n",
    "\n",
    "def related_links(url):\n",
    "    #Import Modules\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import torch\n",
    "    from transformers import BertModel, BertTokenizer\n",
    "    import json\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    \n",
    "    save_directory = \"/Users/david/Desktop/QA Media/Models\"\n",
    "\n",
    "    # Load the model and tokenizer from the directory\n",
    "    model = BertModel.from_pretrained(save_directory)\n",
    "    tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
    "    \n",
    "    # Load the dictionary from a file\n",
    "    with open('dict_file.json', 'r') as file:\n",
    "        articles = json.load(file)\n",
    "        \n",
    "    \n",
    "    if url not in list(articles.keys()):   \n",
    "        article_content = [x for x in articles.values()]\n",
    "\n",
    "        # Function to get embeddings\n",
    "        def get_embeddings(text):\n",
    "            inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "            outputs = model(**inputs)\n",
    "            return outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "\n",
    "        # Assume `documents` is a list of your news articles \n",
    "        with open('arrays.pkl', 'rb') as f:\n",
    "            embeddings = pickle.load(f)\n",
    "\n",
    "        new_url = url\n",
    "\n",
    "        new_response = requests.get(new_url)\n",
    "        new_soup = BeautifulSoup(new_response.text, 'html.parser')\n",
    "        new_text = new_soup.find('meta', attrs={'name': 'description'}).get('content')\n",
    "        if new_url not in list(articles.keys()):\n",
    "            articles[new_url] = new_text\n",
    "\n",
    "        new_embedding = get_embeddings(articles[new_url])\n",
    "\n",
    "        # Compute similarity\n",
    "        similarity_scores = [cosine_similarity(new_embedding, emb) for emb in embeddings]\n",
    "\n",
    "        # Get top 5 similar documents\n",
    "        top_5 = sorted(range(len(similarity_scores)), key=lambda i: similarity_scores[i], reverse=True)[:5]\n",
    "\n",
    "        embeddings.append(new_embedding)\n",
    "\n",
    "        # Save the list of arrays.\n",
    "        with open('arrays.pkl', 'wb') as f:\n",
    "            pickle.dump(embeddings, f)\n",
    "\n",
    "        # Save the dictionary to a file\n",
    "        with open('dict_file.json', 'w') as file:\n",
    "            json.dump(articles, file)\n",
    "\n",
    "        top_5_urls = []\n",
    "\n",
    "        for i in top_5:\n",
    "            top_5_urls.append([x for x in articles.keys()][i])\n",
    "            top_5_urls = [x for x in top_5_urls if x != new_url]\n",
    "            \n",
    "    else:\n",
    "        article_content = [x for x in articles.values()]\n",
    "\n",
    "        # Function to get embeddings\n",
    "        def get_embeddings(text):\n",
    "            inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "            outputs = model(**inputs)\n",
    "            return outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "\n",
    "        # Assume `documents` is a list of your news articles \n",
    "        with open('arrays.pkl', 'rb') as f:\n",
    "            embeddings = pickle.load(f)\n",
    "\n",
    "        new_url = url\n",
    "\n",
    "        new_response = requests.get(new_url)\n",
    "        new_soup = BeautifulSoup(new_response.text, 'html.parser')\n",
    "        new_text = new_soup.find('meta', attrs={'name': 'description'}).get('content')\n",
    "        new_embedding = get_embeddings(articles[new_url])\n",
    "\n",
    "        # Compute similarity\n",
    "        similarity_scores = [cosine_similarity(new_embedding, emb) for emb in embeddings]\n",
    "\n",
    "        # Get top 5 similar documents\n",
    "        top_10 = sorted(range(len(similarity_scores)), key=lambda i: similarity_scores[i], reverse=True)[:10]\n",
    "\n",
    "        top_5_urls = []\n",
    "\n",
    "        for i in top_10:\n",
    "            top_5_urls.append([x for x in articles.keys()][i])\n",
    "            top_5_urls = [x for x in top_5_urls if x != new_url][:5]\n",
    "            \n",
    "    \n",
    "    reading_time = estimate_reading_time(new_text)\n",
    "    #print(f\"Estimated reading time: {reading_time} minutes\")\n",
    "    \n",
    "\n",
    "    return reading_time, top_5_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05ee83e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 14:55:37.441 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/david/opt/anaconda3/envs/Pytorch_env/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '0.0': No scheme supplied. Perhaps you meant http://0.0?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m input_url \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mnumber_input(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter article url:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Calculate the square of the number\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m time, links \u001b[38;5;241m=\u001b[39m \u001b[43mrelated_links\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[1;32m     14\u001b[0m st\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe estimated reading time is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and the URL links are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlinks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36mrelated_links\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     56\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     58\u001b[0m new_url \u001b[38;5;241m=\u001b[39m url\n\u001b[0;32m---> 60\u001b[0m new_response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m new_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(new_response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m new_text \u001b[38;5;241m=\u001b[39m new_soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch_env/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch_env/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch_env/lib/python3.9/site-packages/requests/sessions.py:573\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    561\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    562\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    563\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    571\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    572\u001b[0m )\n\u001b[0;32m--> 573\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    577\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    578\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    579\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch_env/lib/python3.9/site-packages/requests/sessions.py:484\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    481\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    483\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 484\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch_env/lib/python3.9/site-packages/requests/models.py:368\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch_env/lib/python3.9/site-packages/requests/models.py:439\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you meant http://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '0.0': No scheme supplied. Perhaps you meant http://0.0?"
     ]
    }
   ],
   "source": [
    "# Import Streamlit\n",
    "import streamlit as st\n",
    "\n",
    "# Title for the app\n",
    "st.title('Related Article Links App')\n",
    "\n",
    "# Take number input from the user\n",
    "input_url = st.number_input('Enter article url:')\n",
    "\n",
    "# Calculate the square of the number\n",
    "time, links = related_links(input_url)\n",
    "\n",
    "# Display the result\n",
    "st.write(f'The estimated reading time is {time} and the URL links are {links}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "16f0536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated reading time: 4.46 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.qa-financial.com/articles/regulation-round-up-march',\n",
       " 'https://www.qa-financial.com/articles/australia-to-digitise-regulatory-framework',\n",
       " 'https://www.qa-financial.com/articles/software-risk-and-compliance-round-up-june',\n",
       " 'https://www.qa-financial.com/articles/regulation-round-up-april',\n",
       " 'https://www.qa-financial.com/articles/software-risk-management-regulation-round-up-']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_url = 'https://www.qa-financial.com/articles/software-risk-and-compliance-round-up-july'\n",
    "related_links(trial_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
